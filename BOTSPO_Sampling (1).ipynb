{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install zarr\n",
        "!pip install botorch\n",
        "!pip install pyDOE"
      ],
      "metadata": {
        "id": "G8HDxLSHh9oj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc277fd-c9d8-4200-ae5b-24dbe3ca7f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zarr\n",
            "  Downloading zarr-3.1.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting donfig>=0.8 (from zarr)\n",
            "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr)\n",
            "  Downloading numcodecs-0.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from zarr) (2.0.2)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.12/dist-packages (from zarr) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9 in /usr/local/lib/python3.12/dist-packages (from zarr) (4.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr) (6.0.2)\n",
            "Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr)\n",
            "  Downloading crc32c-2.7.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Downloading zarr-3.1.3-py3-none-any.whl (276 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
            "Downloading numcodecs-0.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crc32c-2.7.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numcodecs, donfig, crc32c, zarr\n",
            "Successfully installed crc32c-2.7.1 donfig-0.8.1.post1 numcodecs-0.16.3 zarr-3.1.3\n",
            "Collecting botorch\n",
            "  Downloading botorch-0.15.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from botorch) (4.15.0)\n",
            "Collecting pyre_extensions (from botorch)\n",
            "  Downloading pyre_extensions-0.0.32-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting gpytorch==1.14 (from botorch)\n",
            "  Downloading gpytorch-1.14-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting linear_operator==0.6 (from botorch)\n",
            "  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from botorch) (2.8.0+cu126)\n",
            "Collecting pyro-ppl>=1.8.4 (from botorch)\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from botorch) (1.16.2)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.12/dist-packages (from botorch) (1.0.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.12/dist-packages (from botorch) (3.6.0)\n",
            "Collecting jaxtyping (from gpytorch==1.14->botorch)\n",
            "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.12/dist-packages (from gpytorch==1.14->botorch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from gpytorch==1.14->botorch) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl>=1.8.4->botorch) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.4.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->botorch) (3.4.0)\n",
            "Collecting typing-inspect (from pyre_extensions->botorch)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch==1.14->botorch)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.1->botorch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->gpytorch==1.14->botorch) (1.5.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre_extensions->botorch)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading botorch-0.15.1-py3-none-any.whl (779 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.9/779.9 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gpytorch-1.14-py3-none-any.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.7/277.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyre_extensions-0.0.32-py3-none-any.whl (12 kB)\n",
            "Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Downloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: pyro-api, wadler-lindig, mypy-extensions, typing-inspect, jaxtyping, pyre_extensions, pyro-ppl, linear_operator, gpytorch, botorch\n",
            "Successfully installed botorch-0.15.1 gpytorch-1.14 jaxtyping-0.3.2 linear_operator-0.6 mypy-extensions-1.1.0 pyre_extensions-0.0.32 pyro-api-0.1.2 pyro-ppl-1.9.1 typing-inspect-0.9.0 wadler-lindig-0.1.7\n",
            "Collecting pyDOE\n",
            "  Downloading pyDOE-0.3.8.zip (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pyDOE) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pyDOE) (1.16.2)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-py3-none-any.whl size=18170 sha256=4f3abc846b1e50a175033d0bc470aeae7343357c208ffcd5c679238d426fc6ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/b9/5d/1138ea8c8f212bce6e97ae58847b7cc323145b3277f2129e2b\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: pyDOE\n",
            "Successfully installed pyDOE-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from botorch.fit import fit_gpytorch_model\n",
        "import torch\n",
        "from botorch.models import SingleTaskGP\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.optim import optimize_acqf\n",
        "from botorch.acquisition import UpperConfidenceBound\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "import shutil\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "JRULziQGrxES",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNGghWNhd3gY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "class FourierSeriesGenerator_10:\n",
        "\n",
        "    def __init__(self, total_time=400, time_step=0.002):\n",
        "        self.default_total_time = total_time\n",
        "        self.default_time_step = time_step\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalize(x):\n",
        "        return 2 * (x - np.min(x)) / (np.max(x) - np.min(x)) - 1\n",
        "\n",
        "    @staticmethod\n",
        "    def _rescale(x, min_value, max_value):\n",
        "        return x * (max_value - min_value) + min_value\n",
        "\n",
        "    def fourier_series(self, x, params, rescale_mag=600, rescale_amplitude=50):\n",
        "        x = self._normalize(x)\n",
        "\n",
        "        n, freq, amplitude, phase, trend, seasonality, frequency_slope, amplitude_slope, phase_slope, seasonality_freq = params\n",
        "        n = int(self._rescale(n, 0, 10))\n",
        "        freq = self._rescale(freq, 0, 10)\n",
        "        amplitude = self._rescale(amplitude, 0, 10)\n",
        "        phase = self._rescale(phase, 0, 10000)\n",
        "        trend = self._rescale(trend, -500, 500)\n",
        "        seasonality = self._rescale(seasonality, 0, 500)\n",
        "        frequency_slope = self._rescale(frequency_slope, -1.25, 1.25)\n",
        "        amplitude_slope = self._rescale(amplitude_slope, -1.25, 1.25)\n",
        "        phase_slope = self._rescale(phase_slope, -1.25, 1.25)\n",
        "        seasonality_freq = self._rescale(seasonality_freq, -1, 1)  # Rescale it as per your requirement\n",
        "\n",
        "        sum = np.zeros_like(x)\n",
        "        for i in range(1, n + 1, 2):\n",
        "            term = (1 / i) * np.sin(2 * np.pi * (freq + i * frequency_slope) * i * x + (phase + i * phase_slope))\n",
        "            sum += term\n",
        "\n",
        "        y = (amplitude + n * amplitude_slope) * (2 / np.pi) * sum\n",
        "        if np.sum(y) == 0:\n",
        "            return np.zeros_like(x) + 600\n",
        "        else:\n",
        "            y = (y - np.min(y)) / (np.max(y) - np.min(y))\n",
        "            y = (y * rescale_amplitude) + rescale_mag\n",
        "\n",
        "        y += trend * x\n",
        "        y += seasonality * np.sin(2 * np.pi * seasonality_freq * x)\n",
        "\n",
        "        y = (y - np.min(y)) / (np.max(y) - np.min(y)) # Normalize to [0,1]\n",
        "        y = self._rescale(y, 400, 700) # Rescale to [400,700] due to practical reasons of the laser power profile\n",
        "        return y\n",
        "\n",
        "    def plot_and_save(self, params, base_path, iteration, total_time=None, time_step=None,\n",
        "                      plot_title=None, figsize=(8, 6), xticks=None, yticks=None):\n",
        "        if total_time is None:\n",
        "            total_time = self.default_total_time\n",
        "        if time_step is None:\n",
        "            time_step = self.default_time_step\n",
        "\n",
        "        folder_name = f\"Iteration_{iteration}\"\n",
        "        save_directory = os.path.join(base_path, folder_name)\n",
        "        if not os.path.exists(save_directory):\n",
        "            os.makedirs(save_directory)  # Create directory if it doesn't exist\n",
        "\n",
        "        x = np.linspace(0, total_time, int(total_time / time_step))\n",
        "        y = self.fourier_series(x, params)\n",
        "        # Ensure y values are in the range [400, 700]\n",
        "        y = (y - np.min(y)) / (np.max(y) - np.min(y)) # Normalize to [0,1]\n",
        "        y = self._rescale(y, 400, 700) # Rescale to [400,700] due to practical reasons of the laser power profile\n",
        "\n",
        "        plt.figure(figsize=figsize)\n",
        "\n",
        "        # Create a plot\n",
        "        plt.plot(x[:140000], y[:140000])\n",
        "\n",
        "        # Add title if available\n",
        "        if plot_title:\n",
        "            plt.title(plot_title, fontsize=20)\n",
        "\n",
        "        # Add x and y labels\n",
        "        plt.xlabel(\"Time (Seconds)\", fontsize=20)\n",
        "        plt.ylabel(\"Laser Power as Time \\n Series Profile\", fontsize=20)\n",
        "\n",
        "        # Use provided xticks and yticks if available\n",
        "        if xticks is not None:\n",
        "            plt.xticks(xticks)\n",
        "        if yticks is not None:\n",
        "            plt.yticks(yticks)\n",
        "\n",
        "        plt.xticks(fontsize=20)\n",
        "        plt.yticks(fontsize=20)\n",
        "        plt.title(\"Iteration 50\", fontsize=20)\n",
        "\n",
        "        # Add legend\n",
        "        plt.legend()\n",
        "\n",
        "        image_path = os.path.join(save_directory, \"plot.png\")\n",
        "        plt.savefig(image_path)\n",
        "        plt.show()\n",
        "\n",
        "        output_string = \"laser_power,time_elapsed\\n\"\n",
        "        for i in range(len(x)):\n",
        "            output_string += f\"{y[i]:.15f},{x[i]:.2f}\\n\"\n",
        "        csv_path = os.path.join(save_directory, \"data.csv\")\n",
        "        with open(csv_path, \"w\") as f:\n",
        "            f.write(output_string)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming FourierSeriesGenerator_10 is defined or imported somewhere before this\n",
        "x = np.linspace(0, 400, int(400 / 0.002))\n",
        "fourier_gen = FourierSeriesGenerator_10(total_time=400, time_step=0.002)\n",
        "\n",
        "Laser_power = fourier_gen.fourier_series(x, [0.11, 0.16, 0.69, 0.70, 0.41, 0.09, 0.39, 0.73, 0.16, 0.97])[:150000]\n",
        "\n",
        "plt.plot(x[:150000], Laser_power)\n",
        "plt.show()\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"Tim_Step\": x[:150000],\n",
        "    \"Laser_power\": Laser_power\n",
        "})\n",
        "df.to_csv(\"Optimal_Laser_Power.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "Uy6wBz3deSOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming FourierSeriesGenerator_10 is defined or imported somewhere before this\n",
        "x = np.linspace(0, 400, int(400 / 0.002))\n",
        "fourier_gen = FourierSeriesGenerator_10(total_time=400, time_step=0.002)\n",
        "\n",
        "Laser_power = fourier_gen.fourier_series(x,   [1.,         0.31369773, 0.16385065, 0.1689344,  0.5357304,  0.5076246,\n",
        " 0.58220387, 0.44922945, 0.81219506, 0.2288186 ])[:150000]\n",
        "\n",
        "plt.plot(x[:150000], Laser_power)\n",
        "plt.show()\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"Tim_Step\": x[:150000],\n",
        "    \"Laser_power\": Laser_power\n",
        "})\n",
        "df.to_csv(\"Optimal_Laser_Power.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "jozmwpNdfacX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class TimeSeriesSimulator:\n",
        "    def __init__(self):\n",
        "        # Initialize with any necessary parameters\n",
        "        pass\n",
        "\n",
        "    def process_time_series(self, time_series):\n",
        "        # Process the time series using a combination of advanced techniques\n",
        "        # For demonstration, I'll use a simple mathematical operation with list comprehension\n",
        "        # You can replace this with any complex operation as per your requirement\n",
        "        processed_series = [np.sin(x) + np.cos(x) for x in time_series]\n",
        "        return processed_series\n",
        "\n",
        "    def calculate_output(self, processed_series):\n",
        "        # Calculate a single output value from the processed series\n",
        "        # For example, we could return the mean of the processed series\n",
        "        return np.sum(processed_series)\n",
        "\n",
        "    def simulate(self, time_series):\n",
        "        # The main method to run the simulation\n",
        "        processed = self.process_time_series(time_series)\n",
        "        output = self.calculate_output(processed)\n",
        "        return output\n",
        "\n",
        "# Example usage\n",
        "simulator = TimeSeriesSimulator()\n",
        "time_series_data = np.linspace(0, 10, 100)  # Example time series data\n",
        "result = simulator.simulate(time_series_data)\n",
        "print(f\"Output Value: {result}\")\n"
      ],
      "metadata": {
        "id": "FVtHZfDxlnBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = [1,         0.31369773, 0, 0.1689344,  0.5357304,  0.5076246,\n",
        " 0.58220387, 0.44922945, 0.81219506, 0.2288186 ]\n",
        "\n",
        "def objective(params):\n",
        "    # Create an instance of the simulator with the given parameters\n",
        "    x = np.linspace(0, 400, int(400 / 0.002))\n",
        "    fourier_gen = FourierSeriesGenerator_10(total_time=400, time_step=0.002)\n",
        "    Laser_power = fourier_gen.fourier_series(x, params)\n",
        "    result = simulator.simulate(Laser_power)\n",
        "    # Since Bayesian Optimization typically minimizes,\n",
        "    # if you want to maximize the output, return the negative of the result\n",
        "    return torch.tensor(-result)\n",
        "\n",
        "objective(params)"
      ],
      "metadata": {
        "id": "Axco6D2wpbKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model():\n",
        "    train_X = pd.read_excel(\"optimized_params1.xlsx\")\n",
        "    train_X_np = train_X[[\"n\", \"freq\", \"amplitude\", \"phase\", \"trend\", \"seasonality\", \"frequency_slope\", \"amplitude_slope\", \"phase_slope\", \"Frequnecy of slope\"]].values\n",
        "    train_X_torch = torch.tensor(train_X_np, dtype=torch.float32)\n",
        "    train_Y = pd.read_excel(\"avg_heat_treatment_times.xlsx\")\n",
        "    train_Y_np = train_Y[[\"Average Heat Treatment Time\"]].values\n",
        "    train_Y_torch = torch.tensor(train_Y_np, dtype=torch.float32)\n",
        "    gp = SingleTaskGP(train_X_torch.float(), train_Y_torch.float())\n",
        "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
        "    fit_gpytorch_model(mll)\n",
        "    return gp"
      ],
      "metadata": {
        "id": "8_gQal-RrqVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(initial_data=None):\n",
        "    \"\"\"\n",
        "    Initialize the Gaussian Process model.\n",
        "    If initial_data is provided, it should be a tuple of (initial_params, initial_values).\n",
        "    \"\"\"\n",
        "    if initial_data:\n",
        "        train_X, train_Y = initial_data\n",
        "        train_X = torch.tensor(train_X.astype(np.float32))\n",
        "        train_Y = torch.tensor(train_Y.astype(np.float32)).unsqueeze(-1)\n",
        "    else:\n",
        "        # Define some initial data if none is provided\n",
        "        # Here, you need to replace it with your actual initial data\n",
        "        train_X = torch.rand((10, 10))  # Replace with actual number of parameters\n",
        "        train_Y = torch.rand((10, 1))\n",
        "\n",
        "    gp = SingleTaskGP(train_X, train_Y)\n",
        "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
        "    fit_gpytorch_model(mll)\n",
        "    return gp\n"
      ],
      "metadata": {
        "id": "dk3ZXeKTjwDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize(bounds, n_steps=50):\n",
        "    gp = initialize_model()\n",
        "    best_value = -float('inf')\n",
        "    best_params = None\n",
        "\n",
        "    param_history = []\n",
        "    value_history = []\n",
        "    uncertainty_history = []\n",
        "\n",
        "    # Create an empty dataframe with the required columns\n",
        "    df = pd.DataFrame(columns=['Parameters', 'Objective Value', 'Uncertainty'])\n",
        "\n",
        "    for i in tqdm(range(n_steps)):\n",
        "        UCB = UpperConfidenceBound(gp, beta=0.5)\n",
        "        candidate, _ = optimize_acqf(UCB, bounds=bounds, q=1, num_restarts=5, raw_samples=20)\n",
        "        candidate_numpy = candidate.detach().numpy().flatten()\n",
        "        new_Y = objective(candidate_numpy).unsqueeze(0).unsqueeze(-1)\n",
        "\n",
        "\n",
        "        variance = gp.posterior(candidate).variance\n",
        "        uncertainty_history.append(variance.item())\n",
        "\n",
        "        print(new_Y)\n",
        "        #print(candidate_numpy)\n",
        "\n",
        "\n",
        "        if new_Y.item() > best_value:\n",
        "            best_value = new_Y.item()\n",
        "            best_params = candidate_numpy\n",
        "\n",
        "        param_history.append(candidate_numpy)\n",
        "        value_history.append(new_Y.item())\n",
        "\n",
        "        # Update the Gaussian Process model\n",
        "        gp = SingleTaskGP(\n",
        "            torch.cat([gp.train_inputs[0], torch.tensor(candidate_numpy.astype(np.float32)).unsqueeze(0)]),\n",
        "            torch.cat([gp.train_targets.unsqueeze(-1).float(), new_Y.float()], dim=0)\n",
        "        )\n",
        "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
        "        fit_gpytorch_model(mll)\n",
        "\n",
        "        # Save the current iteration results to the dataframe\n",
        "        #df = df.append({\n",
        "        #    'Current Best Parameters': best_params,\n",
        "        #    'Current Best Value': best_value,\n",
        "        #    'Parameters': candidate_numpy.tolist(),\n",
        "        #    'Objective Value': new_Y.item(),\n",
        "        #    'Uncertainty': variance.item()\n",
        "        #}, ignore_index=True)\n",
        "\n",
        "        # Save the dataframe to an Excel file\n",
        "        #df.to_csv('bayesian_optimization_results.csv', index=False)\n",
        "\n",
        "    return gp, best_params, best_value, param_history, value_history, uncertainty_history"
      ],
      "metadata": {
        "id": "QYscHpKfsVhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 10  # Assuming 10 parameters\n",
        "bounds = torch.tensor([[0]*input_size, [1]*input_size], dtype=torch.float32)\n",
        "optimized_model, best_params, best_value, param_history, value_history, uncertainty_history = optimize(bounds)"
      ],
      "metadata": {
        "id": "ApBDn20qiqc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "# Function to generate a single time series\n",
        "def generate_series(fourier_gen, params):\n",
        "    x = np.linspace(0, 400, int(400 / 0.002))\n",
        "    laser_power = fourier_gen.fourier_series(x, params)[:150000]\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    return scaler.fit_transform(laser_power.reshape(-1, 1))\n",
        "\n",
        "# Generate multiple time series with different parameters\n",
        "series_data = []\n",
        "targets = []\n",
        "for i in range(10):\n",
        "    # Generate different parameters for each series\n",
        "    # Here I'm just adding some variation to the original parameters\n",
        "    params = [1. + i*0.1, 0.31369773, 0.16385065, 0.1689344, 0.5357304, 0.5076246,\n",
        "              0.58220387, 0.44922945, 0.81219506, 0.2288186]\n",
        "\n",
        "    series = generate_series(fourier_gen, params)\n",
        "    series_data.append(series)\n",
        "    targets.append(objective(params))  # Replace with the actual target for each series\n",
        "\n",
        "# Convert to PyTorch tensors and create DataLoader\n",
        "series_data = torch.tensor(np.array(series_data), dtype=torch.float32)\n",
        "# Ensure series_data is in the shape [batch_size, seq_length, num_features]\n",
        "series_data = series_data.reshape((10, -1, 1))  # 10 series, each with seq_length steps and 1 feature\n",
        "\n",
        "# Normalize targets\n",
        "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "targets = target_scaler.fit_transform(np.array(targets).reshape(-1, 1))\n",
        "targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "train_data = TensorDataset(series_data, targets)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=1)\n",
        "\n",
        "\n",
        "# Neural Network Model Definition\n",
        "class TimeSeriesLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(TimeSeriesLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x needs to be of shape (batch, seq_len, features), here seq_len is 1 and features is input_size\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x[:, -1, :])  # Take the last output for prediction\n",
        "        return x\n",
        "\n",
        "# Model Initialization\n",
        "input_size = 1\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "model = TimeSeriesLSTM(input_size, hidden_size, output_size)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train(model, criterion, optimizer, data_loader, epochs=5):\n",
        "    model.train()\n",
        "    epoch_losses = []  # List to store average loss per epoch\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        progress_bar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for i, (series, target) in progress_bar:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(series)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        avg_loss = epoch_loss / len(data_loader)\n",
        "        epoch_losses.append(avg_loss)  # Store the average loss for this epoch\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] completed: Avg. Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return epoch_losses  # Return the list of average losses\n",
        "\n",
        "\n",
        "epoch_losses = train(model, criterion, optimizer, train_loader)\n"
      ],
      "metadata": {
        "id": "m5gkZGHLtnB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_loss_random_search = epoch_losses"
      ],
      "metadata": {
        "id": "0oqKsishZfez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_loss_random_search)"
      ],
      "metadata": {
        "id": "Vh9wLUFv381Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using LHS Sampling"
      ],
      "metadata": {
        "id": "QSdlm4Lh4BKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from pyDOE import lhs\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Function to normalize the parameters generated by LHS\n",
        "def normalize_lhs_params(lhs_sample, param_ranges):\n",
        "    normalized = np.zeros_like(lhs_sample)\n",
        "    for i in range(lhs_sample.shape[1]):\n",
        "        min_val, max_val = param_ranges[i]\n",
        "        normalized[:, i] = min_val + lhs_sample[:, i] * (max_val - min_val)\n",
        "    return normalized\n",
        "\n",
        "# Assuming you have 10 parameters as in your original Fourier series\n",
        "param_ranges = [(0, 1)] * 10  # 10 parameters, each with a range of (0, 1)\n",
        "\n",
        "\n",
        "# Generate LHS samples\n",
        "num_samples = 10\n",
        "lhs_samples = lhs(len(param_ranges), samples=num_samples)\n",
        "params = normalize_lhs_params(lhs_samples, param_ranges)\n",
        "\n",
        "# Generate time series data\n",
        "series_data = []\n",
        "targets = []\n",
        "for param in params:\n",
        "    series = generate_series(fourier_gen, param)\n",
        "    series_data.append(series)\n",
        "    targets.append(objective(param))\n",
        "\n",
        "# Convert to PyTorch tensors and create DataLoader\n",
        "series_data = torch.tensor(np.array(series_data), dtype=torch.float32)\n",
        "# Ensure series_data is in the shape [batch_size, seq_length, num_features]\n",
        "series_data = series_data.reshape((10, -1, 1))  # 10 series, each with seq_length steps and 1 feature\n",
        "\n",
        "# Normalize targets\n",
        "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "targets = target_scaler.fit_transform(np.array(targets).reshape(-1, 1))\n",
        "targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "train_data = TensorDataset(series_data, targets)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=1)\n",
        "\n",
        "\n",
        "# Neural Network Model Definition\n",
        "class TimeSeriesLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(TimeSeriesLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x needs to be of shape (batch, seq_len, features), here seq_len is 1 and features is input_size\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x[:, -1, :])  # Take the last output for prediction\n",
        "        return x\n",
        "\n",
        "# Model Initialization\n",
        "input_size = 1\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "model_LHS = TimeSeriesLSTM(input_size, hidden_size, output_size)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_LHS.parameters(), lr=0.001)\n",
        "\n",
        "def train(model, criterion, optimizer, data_loader, epochs=5):\n",
        "    model.train()\n",
        "    epoch_losses = []  # List to store average loss per epoch\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        progress_bar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for i, (series, target) in progress_bar:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(series)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        avg_loss = epoch_loss / len(data_loader)\n",
        "        epoch_losses.append(avg_loss)  # Store the average loss for this epoch\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] completed: Avg. Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return epoch_losses  # Return the list of average losses\n",
        "\n",
        "\n",
        "epoch_losses = train(model_LHS, criterion, optimizer, train_loader)"
      ],
      "metadata": {
        "id": "V3ZDPlgn4DSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_losses_lhs = epoch_losses\n",
        "plt.plot(epoch_losses_lhs)"
      ],
      "metadata": {
        "id": "hH4YlQwn7wZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Sobol Sequence"
      ],
      "metadata": {
        "id": "IHKb1Rk_P-Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from pyDOE import lhs\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import sobol_seq\n",
        "\n",
        "\n",
        "# Function to normalize the parameters generated by LHS\n",
        "def normalize_lhs_params(lhs_sample, param_ranges):\n",
        "    normalized = np.zeros_like(lhs_sample)\n",
        "    for i in range(lhs_sample.shape[1]):\n",
        "        min_val, max_val = param_ranges[i]\n",
        "        normalized[:, i] = min_val + lhs_sample[:, i] * (max_val - min_val)\n",
        "    return normalized\n",
        "\n",
        "# Assuming you have 10 parameters as in your original Fourier series\n",
        "param_ranges = [(0, 1)] * 10  # 10 parameters, each with a range of (0, 1)\n",
        "\n",
        "num_samples = 10\n",
        "\n",
        "params = sobol_seq.i4_sobol_generate(len(param_ranges), num_samples)\n",
        "params = normalize_lhs_params(params, param_ranges)\n",
        "\n",
        "# Function to generate a single time series\n",
        "def generate_series(fourier_gen, params):\n",
        "    x = np.linspace(0, 400, int(400 / 0.002))\n",
        "    laser_power = fourier_gen.fourier_series(x, params)[:150000]\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    return scaler.fit_transform(laser_power.reshape(-1, 1))\n",
        "\n",
        "# Generate time series data\n",
        "series_data = []\n",
        "targets = []\n",
        "for param in params:\n",
        "    series = generate_series(fourier_gen, param)\n",
        "    series_data.append(series)\n",
        "    targets.append(objective(param))\n",
        "\n",
        "# Convert to PyTorch tensors and create DataLoader\n",
        "series_data = torch.tensor(np.array(series_data), dtype=torch.float32)\n",
        "# Ensure series_data is in the shape [batch_size, seq_length, num_features]\n",
        "series_data = series_data.reshape((10, -1, 1))  # 10 series, each with seq_length steps and 1 feature\n",
        "\n",
        "# Normalize targets\n",
        "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "targets = target_scaler.fit_transform(np.array(targets).reshape(-1, 1))\n",
        "targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "train_data = TensorDataset(series_data, targets)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=1)\n",
        "\n",
        "\n",
        "# Neural Network Model Definition\n",
        "class TimeSeriesLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(TimeSeriesLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x needs to be of shape (batch, seq_len, features), here seq_len is 1 and features is input_size\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x[:, -1, :])  # Take the last output for prediction\n",
        "        return x\n",
        "\n",
        "# Model Initialization\n",
        "input_size = 1\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "model_LHS = TimeSeriesLSTM(input_size, hidden_size, output_size)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_LHS.parameters(), lr=0.001)\n",
        "\n",
        "def train(model, criterion, optimizer, data_loader, epochs=5):\n",
        "    model.train()\n",
        "    epoch_losses = []  # List to store average loss per epoch\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        progress_bar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for i, (series, target) in progress_bar:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(series)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        avg_loss = epoch_loss / len(data_loader)\n",
        "        epoch_losses.append(avg_loss)  # Store the average loss for this epoch\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] completed: Avg. Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return epoch_losses  # Return the list of average losses\n",
        "\n",
        "\n",
        "epoch_losses = train(model_LHS, criterion, optimizer, train_loader)"
      ],
      "metadata": {
        "id": "fXcXhcgtQAnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the BO code"
      ],
      "metadata": {
        "id": "erNwu8tPYcV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = [1,         0.31369773, 0, 0.1689344,  0.5357304,  0.5076246,\n",
        " 0.58220387, 0.44922945, 0.81219506, 0.2288186 ]\n",
        "\n",
        "def objective(params):\n",
        "    # Create an instance of the simulator with the given parameters\n",
        "    x = np.linspace(0, 400, int(400 / 0.002))\n",
        "    fourier_gen = FourierSeriesGenerator_10(total_time=400, time_step=0.002)\n",
        "    Laser_power = fourier_gen.fourier_series(x, params)\n",
        "    result = simulator.simulate(Laser_power)\n",
        "    # Since Bayesian Optimization typically minimizes,\n",
        "    # if you want to maximize the output, return the negative of the result\n",
        "    return torch.tensor(-result)\n",
        "\n",
        "objective(params)"
      ],
      "metadata": {
        "id": "yYPHks6VYF1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize(bounds, n_steps=10, epochs_per_step=1):\n",
        "    gp = initialize_model()\n",
        "    best_value = -float('inf')\n",
        "    best_params = None\n",
        "\n",
        "    param_history = []\n",
        "    value_history = []\n",
        "    uncertainty_history = []\n",
        "    avg_epoch_loss = []\n",
        "\n",
        "    all_series_data = []\n",
        "    all_targets = []\n",
        "\n",
        "    for i in tqdm(range(n_steps)):\n",
        "        UCB = UpperConfidenceBound(gp, beta=1000)\n",
        "        candidate, _ = optimize_acqf(UCB, bounds=bounds, q=1, num_restarts=5, raw_samples=20)\n",
        "        candidate_numpy = candidate.detach().numpy().flatten()\n",
        "        new_Y = objective(candidate_numpy).unsqueeze(0).unsqueeze(-1)\n",
        "\n",
        "        variance = gp.posterior(candidate).variance\n",
        "        uncertainty_history.append(variance.item())\n",
        "\n",
        "        if new_Y.item() > best_value:\n",
        "            best_value = new_Y.item()\n",
        "            best_params = candidate_numpy\n",
        "\n",
        "        param_history.append(candidate_numpy)\n",
        "        value_history.append(new_Y.item())\n",
        "\n",
        "        # Generate time series data for the current parameter set\n",
        "        current_series = generate_series(fourier_gen, candidate_numpy)\n",
        "        all_series_data.append(current_series)\n",
        "        all_targets.append(objective(candidate_numpy))\n",
        "\n",
        "        # Update the Gaussian Process model\n",
        "        gp = SingleTaskGP(\n",
        "            torch.cat([gp.train_inputs[0], torch.tensor(candidate_numpy.astype(np.float32)).unsqueeze(0)]),\n",
        "            torch.cat([gp.train_targets.unsqueeze(-1).float(), new_Y.float()], dim=0)\n",
        "        )\n",
        "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
        "        fit_gpytorch_model(mll)\n",
        "\n",
        "    # Normalize all targets\n",
        "    target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    all_targets = target_scaler.fit_transform(np.array(all_targets).reshape(-1, 1))\n",
        "    all_targets = torch.tensor(all_targets, dtype=torch.float32)\n",
        "\n",
        "    # Convert all series data to PyTorch tensors\n",
        "    all_series_data = torch.tensor(np.array(all_series_data), dtype=torch.float32)\n",
        "    all_series_data = all_series_data.reshape((-1, 150000, 1))  # Reshape for LSTM input\n",
        "\n",
        "    # Create DataLoader for all collected data\n",
        "    train_data = TensorDataset(all_series_data, all_targets)\n",
        "    print(all_series_data.shape)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_data, batch_size=1)\n",
        "\n",
        "    # Train the LSTM model on the collected data\n",
        "    for epoch in range(epochs_per_step):\n",
        "        epoch_losses = train(model_LHS, criterion, optimizer, train_loader)\n",
        "        avg_epoch_loss.append(epoch_losses)\n",
        "\n",
        "    return gp, best_params, best_value, param_history, value_history, uncertainty_history, avg_epoch_loss\n",
        "\n",
        "\n",
        "\n",
        "def train(model, criterion, optimizer, data_loader, epochs=5):\n",
        "    model.train()\n",
        "    epoch_losses = []  # List to store average loss per epoch\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        progress_bar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for i, (series, target) in progress_bar:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(series)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        avg_loss = epoch_loss / len(data_loader)\n",
        "        epoch_losses.append(avg_loss)  # Store the average loss for this epoch\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] completed: Avg. Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return epoch_losses  # Return the list of average losses\n",
        "\n",
        "input_size = 10  # Assuming 10 parameters\n",
        "bounds = torch.tensor([[0]*input_size, [1]*input_size], dtype=torch.float32)\n",
        "optimized_model, best_params, best_value, param_history, value_history, uncertainty_history, epoch_losses = optimize(bounds)\n"
      ],
      "metadata": {
        "id": "TDrRa6bQY_3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_loss_BO = epoch_losses[0]"
      ],
      "metadata": {
        "id": "C_PmWqAtkfHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_loss_BO)"
      ],
      "metadata": {
        "id": "ql_8Uj3mdekI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The range for your epochs\n",
        "epochs = range(1, len(epoch_loss_random_search) + 1)\n",
        "\n",
        "# Plotting the losses\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, epoch_loss_random_search, marker='o', label='Random Search')\n",
        "plt.plot(epochs, epoch_losses_lhs, marker='s', label='LHS')\n",
        "plt.plot(epochs, epoch_loss_BO, marker='^', label='Bayesian Optimization')\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('Comparison of Losses Across Sampling Methods')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nj2HAWGlao3n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}